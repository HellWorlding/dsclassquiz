{
  "meta": {
    "course": "경영데이터과학론심화",
    "tool": "Orange3",
    "quiz_id": "10-2",
    "version": "1.0",
    "source": "문제/해설 분리 파일 병합"
  },
  "questions": [
    {
      "qid": "10-2-Q01",
      "type": "mcq",
      "prompt": "Gradient Boosting의 기본 원리에 대한 설명으로 가장 적절한 것은 무엇인가?",
      "choices": [
        { "cid": "A", "text": "하나의 강한 학습기를 한 번에 학습시켜 예측 성능을 높인다" },
        { "cid": "B", "text": "약한 학습기를 병렬적으로 학습시켜 평균을 낸다" },
        { "cid": "C", "text": "이전 모델의 오차를 보완하는 방향으로 약한 학습기를 순차적으로 추가한다" },
        { "cid": "D", "text": "모든 특성을 동일한 중요도로 가정하여 모델을 구성한다" }
      ]
    },
    {
      "qid": "10-2-Q02",
      "type": "mcq",
      "prompt": "Gradient Boosting에서 ‘잔차(residual)’의 역할로 가장 알맞은 것은?",
      "choices": [
        { "cid": "A", "text": "입력 변수의 스케일을 조정하는 값" },
        { "cid": "B", "text": "이전 모델이 예측하지 못한 오차 정보" },
        { "cid": "C", "text": "모델의 최종 성능 지표" },
        { "cid": "D", "text": "과적합을 방지하기 위한 규제 항목" }
      ]
    },
    {
      "qid": "10-2-Q03",
      "type": "mcq",
      "prompt": "XGBoost의 특징으로 옳지 않은 것은 무엇인가?",
      "choices": [
        { "cid": "A", "text": "정규화(regularization)를 통해 과적합을 제어한다" },
        { "cid": "B", "text": "결측치를 자동으로 처리할 수 있다" },
        { "cid": "C", "text": "순차 학습만 가능하여 속도가 느리다" },
        { "cid": "D", "text": "조기 종료(early stopping)를 통해 과적합을 방지한다" }
      ]
    },
    {
      "qid": "10-2-Q04",
      "type": "mcq",
      "prompt": "XGBoost에서 regularization(λ)을 크게 설정했을 때 일반적으로 나타나는 현상은?",
      "choices": [
        { "cid": "A", "text": "모델이 복잡해지고 과적합 가능성이 증가한다" },
        { "cid": "B", "text": "모델이 단순해지고 과소적합 가능성이 증가한다" },
        { "cid": "C", "text": "학습 속도가 느려지고 성능은 항상 향상된다" },
        { "cid": "D", "text": "feature importance 해석이 불가능해진다" }
      ]
    },
    {
      "qid": "10-2-Q05",
      "type": "mcq",
      "prompt": "Feature Importance를 사용하는 가장 주요한 목적은 무엇인가?",
      "choices": [
        { "cid": "A", "text": "데이터 수를 증가시키기 위해" },
        { "cid": "B", "text": "모델의 예측 속도를 느리게 하기 위해" },
        { "cid": "C", "text": "예측에 중요한 변수를 식별하기 위해" },
        { "cid": "D", "text": "타깃 변수를 자동 생성하기 위해" }
      ]
    },
    {
      "qid": "10-2-Q06",
      "type": "mcq",
      "prompt": "AUC(Area Under Curve)에 대한 설명으로 가장 적절한 것은?",
      "choices": [
        { "cid": "A", "text": "0에 가까울수록 분류 성능이 우수하다" },
        { "cid": "B", "text": "0.5는 무작위 분류 수준을 의미한다" },
        { "cid": "C", "text": "값의 범위는 음수에서 1까지이다" },
        { "cid": "D", "text": "회귀 분석에서만 사용된다" }
      ]
    },
    {
      "qid": "10-2-Q07",
      "type": "mcq",
      "prompt": "Orange3에서 XAI(설명가능한 인공지능)의 필요성으로 가장 거리가 먼 것은?",
      "choices": [
        { "cid": "A", "text": "모델 판단의 신뢰성 확보" },
        { "cid": "B", "text": "모델 오류 및 편향 탐지" },
        { "cid": "C", "text": "규제 및 책임성 대응" },
        { "cid": "D", "text": "모델 학습 시간을 증가시키기 위함" }
      ]
    },
    {
      "qid": "10-2-Q08",
      "type": "mcq",
      "prompt": "XGBoost와 Logit Regression을 함께 사용하는 이유로 가장 적절한 것은?",
      "choices": [
        { "cid": "A", "text": "예측 정확도를 무조건 100%로 만들기 위해" },
        { "cid": "B", "text": "Feature Importance 결과를 통계적으로 해석하기 위해" },
        { "cid": "C", "text": "데이터를 자동으로 증식하기 위해" },
        { "cid": "D", "text": "Orange3 설치 오류를 해결하기 위해" }
      ]
    },
    {
      "qid": "10-2-Q09",
      "type": "short",
      "prompt": "XAI의 핵심 목적을 한 문장으로 서술하시오."
    },
    {
      "qid": "10-2-Q10",
      "type": "essay",
      "prompt": "XGBoost 기반 Feature Importance 분석 후 Logit Regression을 추가로 수행하는 것이 왜 연구적으로 의미 있는지 설명하시오."
    }
  ],
  "answers": [
    { "qid": "10-2-Q01", "correct": "C" },
    { "qid": "10-2-Q02", "correct": "B" },
    { "qid": "10-2-Q03", "correct": "C" },
    { "qid": "10-2-Q04", "correct": "B" },
    { "qid": "10-2-Q05", "correct": "C" },
    { "qid": "10-2-Q06", "correct": "B" },
    { "qid": "10-2-Q07", "correct": "D" },
    { "qid": "10-2-Q08", "correct": "B" },
    {
      "qid": "10-2-Q09",
      "correct": [
        "모델의 예측 결과를 사람이 이해할 수 있도록 설명하는 것",
        "머신러닝 모델의 판단 근거를 설명하는 것"
      ]
    },
    {
      "qid": "10-2-Q10",
      "correct": "rubric"
    }
  ],
  "explanations": [
    {
      "qid": "10-2-Q01",
      "explanation": "Gradient Boosting은 이전 모델의 실수를 보완하는 방향으로 약한 학습기를 순차적으로 추가한다."
    },
    {
      "qid": "10-2-Q02",
      "explanation": "잔차는 이전 모델이 설명하지 못한 오차 정보로, 다음 모델이 학습할 핵심 대상이다."
    },
    {
      "qid": "10-2-Q03",
      "explanation": "XGBoost는 병렬 학습과 최적화를 통해 빠른 속도를 제공한다."
    },
    {
      "qid": "10-2-Q04",
      "explanation": "정규화가 강해질수록 모델은 단순해져 과소적합 위험이 증가한다."
    },
    {
      "qid": "10-2-Q05",
      "explanation": "Feature Importance는 예측에 중요한 변수를 식별하는 데 목적이 있다."
    },
    {
      "qid": "10-2-Q06",
      "explanation": "AUC 0.5는 무작위 분류기의 성능 기준선이다."
    },
    {
      "qid": "10-2-Q07",
      "explanation": "XAI의 목적은 설명·신뢰·책임성 확보이지 학습 시간 증가가 아니다."
    },
    {
      "qid": "10-2-Q08",
      "explanation": "Logit Regression은 변수 계수와 통계적 유의성을 통해 Feature Importance 결과를 해석 보완한다."
    },
    {
      "qid": "10-2-Q09",
      "explanation": "XAI는 모델의 예측 결과가 왜 나왔는지를 사람이 이해할 수 있도록 설명하는 것을 목표로 한다."
    },
    {
      "qid": "10-2-Q10",
      "explanation": "XGBoost는 예측력 중심, Logit Regression은 계수 해석과 통계적 설명에 강점이 있어 책임 있는 의사결정이 가능하다."
    }
  ]
}
